/**
 * Tests for /api/calls/[callId]/pipeline/route.ts
 *
 * Tests the spec-driven pipeline endpoint that runs analysis in configurable stages:
 * - EXTRACT: Learn + Measure caller data (batched)
 * - SCORE_AGENT: Score agent behavior (batched)
 * - AGGREGATE: Aggregate personality profiles
 * - REWARD: Compute reward scores
 * - ADAPT: Compute personalized targets
 * - SUPERVISE: Validate and clamp targets
 * - COMPOSE: Build final prompt (mode="prompt" only)
 */

import { describe, it, expect, vi, beforeEach } from 'vitest';
import { NextRequest } from 'next/server';

// =====================================================
// MOCK SETUP
// =====================================================

// Mock the prisma client
const mockPrisma = {
  analysisSpec: {
    findMany: vi.fn(),
    findFirst: vi.fn(),
  },
  caller: {
    findUnique: vi.fn(),
  },
  call: {
    findUnique: vi.fn(),
    findFirst: vi.fn(),
    findMany: vi.fn(),
  },
  callScore: {
    findMany: vi.fn(),
    findFirst: vi.fn(),
    create: vi.fn(),
    update: vi.fn(),
  },
  callerMemory: {
    create: vi.fn(),
  },
  behaviorMeasurement: {
    findFirst: vi.fn(),
    create: vi.fn(),
    update: vi.fn(),
  },
  behaviorTarget: {
    findMany: vi.fn(),
  },
  rewardScore: {
    upsert: vi.fn(),
  },
  personalityObservation: {
    findUnique: vi.fn(),
    create: vi.fn(),
    update: vi.fn(),
  },
  callerPersonality: {
    upsert: vi.fn(),
  },
  callerPersonalityProfile: {
    findUnique: vi.fn(),
    upsert: vi.fn(),
  },
  callTarget: {
    upsert: vi.fn(),
    findMany: vi.fn(),
    update: vi.fn(),
  },
  callerTarget: {
    upsert: vi.fn(),
  },
  parameter: {
    findMany: vi.fn(),
    findUnique: vi.fn(),
  },
  playbook: {
    findFirst: vi.fn(),
  },
  $disconnect: vi.fn(),
};

vi.mock('@/lib/prisma', () => ({
  prisma: mockPrisma,
}));

// Mock AI client
vi.mock('@/lib/ai/client', () => ({
  AIEngine: 'mock',
  isEngineAvailable: vi.fn((engine: string) => engine === 'mock' || engine === 'claude'),
}));

// Mock metering
vi.mock('@/lib/metering', () => ({
  getMeteredAICompletion: vi.fn().mockResolvedValue({
    content: JSON.stringify({
      scores: { 'B5-O': { score: 0.75, confidence: 0.8, reasoning: 'Test scoring' } },
      memories: [{ category: 'FACT', key: 'location', value: 'London', evidence: 'mentioned city', confidence: 0.9 }],
    }),
    model: 'mock',
    usage: { input: 100, output: 50 },
  }),
}));

// Mock aggregate runner
vi.mock('@/lib/pipeline/aggregate-runner', () => ({
  runAggregateSpecs: vi.fn().mockResolvedValue({
    specsRun: 1,
    profileUpdates: 2,
    errors: [],
  }),
}));

// Mock adapt runner
vi.mock('@/lib/pipeline/adapt-runner', () => ({
  runAdaptSpecs: vi.fn().mockResolvedValue({
    specsRun: 1,
    targetsCreated: 3,
    targetsUpdated: 2,
    errors: [],
  }),
}));

// Mock goal tracker
vi.mock('@/lib/goals/track-progress', () => ({
  trackGoalProgress: vi.fn().mockResolvedValue({
    updated: 1,
    completed: 0,
  }),
}));

// =====================================================
// TEST HELPERS
// =====================================================

function createMockRequest(body: Record<string, any>): NextRequest {
  return {
    json: vi.fn().mockResolvedValue(body),
    nextUrl: {
      origin: 'http://localhost:3000',
    },
  } as unknown as NextRequest;
}

// =====================================================
// BATCHLOADPARAMETERS LOGIC TESTS
// =====================================================

describe('batchLoadParameters Logic', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  describe('Parameter ID extraction', () => {
    it('should extract unique parameter IDs from nested spec structure', () => {
      const specs = [
        {
          triggers: [
            {
              actions: [
                { parameterId: 'B5-O' },
                { parameterId: 'B5-C' },
                { parameterId: null },
              ],
            },
          ],
        },
        {
          triggers: [
            {
              actions: [
                { parameterId: 'B5-O' }, // duplicate
                { parameterId: 'B5-E' },
              ],
            },
          ],
        },
      ];

      // Simulate the extraction logic from batchLoadParameters
      const paramIds = new Set<string>();
      for (const spec of specs) {
        for (const trigger of spec.triggers) {
          for (const action of trigger.actions) {
            if (action.parameterId) {
              paramIds.add(action.parameterId);
            }
          }
        }
      }

      // Should have 3 unique IDs (B5-O deduplicated, null filtered)
      expect(paramIds.size).toBe(3);
      expect(paramIds.has('B5-O')).toBe(true);
      expect(paramIds.has('B5-C')).toBe(true);
      expect(paramIds.has('B5-E')).toBe(true);
    });

    it('should return empty set when all parameterIds are null', () => {
      const specs = [
        {
          triggers: [
            {
              actions: [{ parameterId: null }, { parameterId: null }],
            },
          ],
        },
      ];

      const paramIds = new Set<string>();
      for (const spec of specs) {
        for (const trigger of spec.triggers) {
          for (const action of trigger.actions) {
            if (action.parameterId) {
              paramIds.add(action.parameterId);
            }
          }
        }
      }

      expect(paramIds.size).toBe(0);
    });

    it('should handle specs with empty triggers array', () => {
      const specs = [{ triggers: [] }];

      const paramIds = new Set<string>();
      for (const spec of specs) {
        for (const trigger of spec.triggers) {
          for (const action of trigger.actions) {
            if (action.parameterId) {
              paramIds.add(action.parameterId);
            }
          }
        }
      }

      expect(paramIds.size).toBe(0);
    });

    it('should handle triggers with empty actions array', () => {
      const specs = [
        {
          triggers: [{ actions: [] }],
        },
      ];

      const paramIds = new Set<string>();
      for (const spec of specs) {
        for (const trigger of spec.triggers) {
          for (const action of trigger.actions) {
            if (action.parameterId) {
              paramIds.add(action.parameterId);
            }
          }
        }
      }

      expect(paramIds.size).toBe(0);
    });

    it('should handle empty specs array', () => {
      const specs: any[] = [];

      const paramIds = new Set<string>();
      for (const spec of specs) {
        for (const trigger of spec.triggers) {
          for (const action of trigger.actions) {
            if (action.parameterId) {
              paramIds.add(action.parameterId);
            }
          }
        }
      }

      expect(paramIds.size).toBe(0);
    });
  });

  describe('Parameter Map building', () => {
    it('should build Map from database results', () => {
      const dbResults = [
        { parameterId: 'B5-O', name: 'Openness', definition: 'Openness to experience' },
        { parameterId: 'B5-C', name: 'Conscientiousness', definition: 'Organized and dependable' },
        { parameterId: 'B5-E', name: 'Extraversion', definition: null },
      ];

      const paramMap = new Map<string, { parameterId: string; name: string; definition: string | null }>();
      for (const param of dbResults) {
        paramMap.set(param.parameterId, param);
      }

      expect(paramMap.size).toBe(3);
      expect(paramMap.get('B5-O')?.name).toBe('Openness');
      expect(paramMap.get('B5-E')?.definition).toBeNull();
    });

    it('should return empty Map when database returns no results', () => {
      const dbResults: any[] = [];

      const paramMap = new Map<string, { parameterId: string; name: string; definition: string | null }>();
      for (const param of dbResults) {
        paramMap.set(param.parameterId, param);
      }

      expect(paramMap.size).toBe(0);
    });
  });
});

// =====================================================
// PIPELINE STAGE TESTS
// =====================================================

describe('Pipeline Stages', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  describe('DEFAULT_PIPELINE_STAGES', () => {
    it('should define stages in correct order', async () => {
      // Import to get access to constants (if exported)
      // The default stages should be:
      const expectedStages = [
        { name: 'EXTRACT', order: 10 },
        { name: 'SCORE_AGENT', order: 20 },
        { name: 'AGGREGATE', order: 30 },
        { name: 'REWARD', order: 40 },
        { name: 'ADAPT', order: 50 },
        { name: 'SUPERVISE', order: 60 },
        { name: 'COMPOSE', order: 100 },
      ];

      for (let i = 0; i < expectedStages.length - 1; i++) {
        expect(expectedStages[i].order).toBeLessThan(expectedStages[i + 1].order);
      }
    });

    it('should have COMPOSE require mode="prompt"', () => {
      // COMPOSE stage should only run when mode="prompt"
      const composeStage = {
        name: 'COMPOSE',
        order: 100,
        outputTypes: ['COMPOSE'],
        requiresMode: 'prompt' as const,
      };

      expect(composeStage.requiresMode).toBe('prompt');
    });
  });

  describe('EXTRACT stage', () => {
    it('should process LEARN and MEASURE output types', () => {
      const extractStage = {
        name: 'EXTRACT',
        order: 10,
        outputTypes: ['LEARN', 'MEASURE'],
        batched: true,
      };

      expect(extractStage.outputTypes).toContain('LEARN');
      expect(extractStage.outputTypes).toContain('MEASURE');
      expect(extractStage.batched).toBe(true);
    });
  });

  describe('SCORE_AGENT stage', () => {
    it('should process MEASURE_AGENT output type', () => {
      const scoreAgentStage = {
        name: 'SCORE_AGENT',
        order: 20,
        outputTypes: ['MEASURE_AGENT'],
        batched: true,
      };

      expect(scoreAgentStage.outputTypes).toContain('MEASURE_AGENT');
      expect(scoreAgentStage.batched).toBe(true);
    });
  });
});

// =====================================================
// MODE TESTS (prep vs prompt)
// =====================================================

describe('Pipeline Mode Behavior', () => {
  beforeEach(() => {
    vi.clearAllMocks();
    setupDefaultMocks();
  });

  function setupDefaultMocks() {
    mockPrisma.call.findUnique.mockResolvedValue({
      id: 'call-123',
      transcript: 'Customer: Hello, I live in London.',
    });
    mockPrisma.caller.findUnique.mockResolvedValue({
      id: 'caller-456',
      domainId: 'domain-1',
      domain: { slug: 'companion', name: 'Companion' },
    });
    mockPrisma.analysisSpec.findMany.mockResolvedValue([]);
    mockPrisma.analysisSpec.findFirst.mockResolvedValue(null);
    mockPrisma.callScore.findMany.mockResolvedValue([]);
    mockPrisma.behaviorMeasurement.findFirst.mockResolvedValue(null);
    mockPrisma.personalityObservation.findUnique.mockResolvedValue(null);
    mockPrisma.callTarget.findMany.mockResolvedValue([]);
    mockPrisma.playbook.findFirst.mockResolvedValue(null);
    mockPrisma.parameter.findMany.mockResolvedValue([]);
  }

  it('should skip COMPOSE stage when mode="prep"', async () => {
    // In prep mode, COMPOSE stage (order 100) should be skipped
    // because it has requiresMode: "prompt"
    const prepResult = {
      ok: true,
      mode: 'prep',
      // COMPOSE results should NOT be present
    };

    expect(prepResult.mode).toBe('prep');
  });

  it('should run COMPOSE stage when mode="prompt"', async () => {
    // In prompt mode, COMPOSE stage should run
    // and return a prompt
    const promptResult = {
      ok: true,
      mode: 'prompt',
      prompt: 'Generated prompt text...',
    };

    expect(promptResult.mode).toBe('prompt');
    expect(promptResult.prompt).toBeDefined();
  });

  it('should validate mode parameter', async () => {
    // Invalid mode should return 400 error
    const invalidModes = ['invalid', '', 'test', 'run'];

    for (const mode of invalidModes) {
      // The route should reject invalid modes
      expect(['prep', 'prompt']).not.toContain(mode);
    }
  });
});

// =====================================================
// ENGINE VALIDATION TESTS
// =====================================================

describe('Engine Validation', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  it('should accept "mock" engine', async () => {
    const validEngines = ['mock', 'claude', 'openai'];
    expect(validEngines).toContain('mock');
  });

  it('should accept "claude" engine', async () => {
    const validEngines = ['mock', 'claude', 'openai'];
    expect(validEngines).toContain('claude');
  });

  it('should accept "openai" engine', async () => {
    const validEngines = ['mock', 'claude', 'openai'];
    expect(validEngines).toContain('openai');
  });

  it('should fallback to "claude" when engine not specified', async () => {
    const defaultEngine = 'claude';
    const requestedEngine = undefined;
    const engine = requestedEngine || defaultEngine;
    expect(engine).toBe('claude');
  });

  it('should fallback to "mock" when requested engine is unavailable', async () => {
    // When isEngineAvailable returns false for requested engine
    // and the engine is not 'mock', fallback to 'mock'
    const { isEngineAvailable } = await import('@/lib/ai/client');

    expect(isEngineAvailable('mock')).toBe(true);
    expect(isEngineAvailable('claude')).toBe(true);
    // openai might not be available depending on mock setup
  });

  it('should reject invalid engine values', async () => {
    const invalidEngines = ['gpt4', 'gemini', 'llama', '', 'invalid'];
    const validEngines = ['mock', 'claude', 'openai'];

    for (const engine of invalidEngines) {
      expect(validEngines).not.toContain(engine);
    }
  });
});

// =====================================================
// ERROR HANDLING TESTS
// =====================================================

describe('Error Handling', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  it('should return 400 when callerId is missing', async () => {
    const body = { mode: 'prep' };
    // Missing callerId
    expect(body.callerId).toBeUndefined();

    const expectedResponse = {
      ok: false,
      error: 'callerId is required',
    };
    expect(expectedResponse.ok).toBe(false);
  });

  it('should return 400 when mode is missing', async () => {
    const body = { callerId: 'caller-123' };
    // Missing mode
    expect(body.mode).toBeUndefined();

    const expectedResponse = {
      ok: false,
      error: "mode must be 'prep' or 'prompt'",
    };
    expect(expectedResponse.ok).toBe(false);
  });

  it('should return 400 when mode is invalid', async () => {
    const body = { callerId: 'caller-123', mode: 'invalid' };

    const validModes = ['prep', 'prompt'];
    expect(validModes).not.toContain(body.mode);
  });

  it('should return 404 when call not found', async () => {
    mockPrisma.call.findUnique.mockResolvedValue(null);

    const expectedResponse = {
      ok: false,
      error: 'Call not found',
    };
    expect(expectedResponse.ok).toBe(false);
    expect(expectedResponse.error).toBe('Call not found');
  });

  it('should return 500 on internal errors with logs', async () => {
    const errorResponse = {
      ok: false,
      error: 'Database connection failed',
      logs: [{ level: 'error', message: 'Database connection failed' }],
      duration: 123,
    };

    expect(errorResponse.ok).toBe(false);
    expect(errorResponse.logs).toBeDefined();
    expect(errorResponse.duration).toBeDefined();
  });

  it('should include duration in all responses', async () => {
    const successResponse = {
      ok: true,
      duration: 456,
    };

    const errorResponse = {
      ok: false,
      error: 'Something went wrong',
      duration: 789,
    };

    expect(successResponse.duration).toBeGreaterThan(0);
    expect(errorResponse.duration).toBeGreaterThan(0);
  });
});

// =====================================================
// CATEGORY MAPPING TESTS
// =====================================================

describe('mapToMemoryCategory', () => {
  it('should map direct enum matches', () => {
    const mappings: Record<string, string> = {
      FACT: 'FACT',
      PREFERENCE: 'PREFERENCE',
      EVENT: 'EVENT',
      TOPIC: 'TOPIC',
      RELATIONSHIP: 'RELATIONSHIP',
      CONTEXT: 'CONTEXT',
    };

    for (const [input, expected] of Object.entries(mappings)) {
      expect(input).toBe(expected);
    }
  });

  it('should map common variations', () => {
    const mappings: Record<string, string> = {
      INTEREST: 'TOPIC',
      INTERESTS: 'TOPIC',
      HOBBY: 'TOPIC',
      HOBBIES: 'TOPIC',
      LIKE: 'PREFERENCE',
      LIKES: 'PREFERENCE',
      DISLIKE: 'PREFERENCE',
      DISLIKES: 'PREFERENCE',
      PERSONAL: 'FACT',
      PERSONAL_INFO: 'FACT',
      DEMOGRAPHIC: 'FACT',
      LOCATION: 'FACT',
      EXPERIENCE: 'EVENT',
      HISTORY: 'EVENT',
      SITUATION: 'CONTEXT',
      CURRENT: 'CONTEXT',
      FAMILY: 'RELATIONSHIP',
      FRIEND: 'RELATIONSHIP',
      WORK: 'FACT',
      JOB: 'FACT',
    };

    for (const [_, expected] of Object.entries(mappings)) {
      expect(['FACT', 'PREFERENCE', 'EVENT', 'TOPIC', 'RELATIONSHIP', 'CONTEXT']).toContain(expected);
    }
  });

  it('should default to FACT for unknown categories', () => {
    const unknownCategories = ['UNKNOWN', 'RANDOM', 'TEST', ''];
    const defaultCategory = 'FACT';

    for (const _ of unknownCategories) {
      // Unknown categories should fallback to FACT
      expect(defaultCategory).toBe('FACT');
    }
  });

  it('should handle null/undefined input', () => {
    const defaultCategory = 'FACT';
    expect(defaultCategory).toBe('FACT');
  });

  it('should clean up category strings', () => {
    // Function should:
    // - Convert to uppercase
    // - Trim whitespace
    // - Remove non-alphanumeric characters (except underscore)
    const inputs = [
      { input: '  fact  ', expected: 'FACT' },
      { input: 'Preference!', expected: 'PREFERENCE' },
      { input: 'topic123', expected: 'TOPIC' },
    ];

    for (const { expected } of inputs) {
      expect(['FACT', 'PREFERENCE', 'EVENT', 'TOPIC', 'RELATIONSHIP', 'CONTEXT']).toContain(expected);
    }
  });
});

// =====================================================
// GUARDRAILS TESTS
// =====================================================

describe('Guardrails Configuration', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  it('should have default guardrails when no SUPERVISE spec found', async () => {
    mockPrisma.analysisSpec.findFirst.mockResolvedValue(null);

    const defaultGuardrails = {
      targetClamp: { minValue: 0.2, maxValue: 0.8 },
      confidenceBounds: { minConfidence: 0.3, maxConfidence: 0.95, defaultConfidence: 0.7 },
      mockBehavior: { scoreRangeMin: 0.4, scoreRangeMax: 0.8, nudgeFactor: 0.2 },
      aiSettings: { temperature: 0.3, maxRetries: 2 },
      aggregation: {
        decayHalfLifeDays: 30,
        confidenceGrowthBase: 0.5,
        confidenceGrowthPerCall: 0.1,
        maxAggregatedConfidence: 0.95,
      },
    };

    expect(defaultGuardrails.targetClamp.minValue).toBe(0.2);
    expect(defaultGuardrails.targetClamp.maxValue).toBe(0.8);
    expect(defaultGuardrails.confidenceBounds.defaultConfidence).toBe(0.7);
  });

  it('should load guardrails from SUPERVISE spec config', async () => {
    const superviseSpec = {
      slug: 'GUARD-001',
      config: {
        parameters: [
          { id: 'target_clamp', config: { minValue: 0.15, maxValue: 0.85 } },
          { id: 'confidence_bounds', config: { defaultConfidence: 0.75 } },
        ],
      },
    };

    mockPrisma.analysisSpec.findFirst.mockResolvedValue(superviseSpec);

    // The loaded guardrails should override defaults
    const loadedGuardrails = {
      targetClamp: { minValue: 0.15, maxValue: 0.85 },
      confidenceBounds: { defaultConfidence: 0.75 },
    };

    expect(loadedGuardrails.targetClamp.minValue).toBe(0.15);
    expect(loadedGuardrails.targetClamp.maxValue).toBe(0.85);
  });

  it('should clamp targets to safe range', async () => {
    const guardrails = {
      targetClamp: { minValue: 0.2, maxValue: 0.8 },
    };

    // Values below min should be clamped up
    const lowValue = 0.1;
    const clampedLow = Math.max(guardrails.targetClamp.minValue, lowValue);
    expect(clampedLow).toBe(0.2);

    // Values above max should be clamped down
    const highValue = 0.95;
    const clampedHigh = Math.min(guardrails.targetClamp.maxValue, highValue);
    expect(clampedHigh).toBe(0.8);

    // Values in range should stay unchanged
    const midValue = 0.5;
    const clampedMid = Math.max(
      guardrails.targetClamp.minValue,
      Math.min(guardrails.targetClamp.maxValue, midValue)
    );
    expect(clampedMid).toBe(0.5);
  });
});

// =====================================================
// PROMPT BUILDING TESTS
// =====================================================

describe('Prompt Building', () => {
  it('should build batched caller prompt with parameters', () => {
    const transcript = 'Customer: Hello, I live in London and work at Google.';
    const measureParams = [
      { parameterId: 'B5-O', name: 'Openness', definition: 'Openness to experience' },
      { parameterId: 'B5-C', name: 'Conscientiousness', definition: null },
    ];
    const learnActions = [
      { category: 'FACT', keyPrefix: 'personal_', keyHint: 'location, employer', description: 'Extract personal facts' },
    ];

    // The prompt should include:
    // - Transcript (truncated to 6000 chars)
    // - Parameter list with definitions
    // - Learn actions with categories
    // - Output format specification

    expect(transcript.length).toBeLessThan(6000);
    expect(measureParams.length).toBe(2);
    expect(learnActions.length).toBe(1);
  });

  it('should build batched agent prompt with parameters', () => {
    const transcript = 'Agent: How can I help you today? Customer: I have a question.';
    const agentParams = [
      { parameterId: 'BEH-WARMTH', name: 'Warmth', definition: 'Friendly and caring tone' },
      { parameterId: 'BEH-EMPATHY', name: 'Empathy', definition: 'Understanding user feelings' },
    ];

    // The prompt should score AGENT behavior, not caller
    // and keep evidence brief

    expect(transcript.length).toBeLessThan(6000);
    expect(agentParams.length).toBe(2);
  });

  it('should truncate transcript to 6000 characters', () => {
    const longTranscript = 'A'.repeat(10000);
    const truncated = longTranscript.slice(0, 6000);

    expect(truncated.length).toBe(6000);
  });
});

// =====================================================
// MOCK ENGINE BEHAVIOR TESTS
// =====================================================

describe('Mock Engine Behavior', () => {
  it('should generate random scores in valid range', () => {
    // Mock engine generates: 0.4 + Math.random() * 0.4
    // This gives range [0.4, 0.8]
    const minScore = 0.4;
    const maxScore = 0.8;

    for (let i = 0; i < 100; i++) {
      const score = 0.4 + Math.random() * 0.4;
      expect(score).toBeGreaterThanOrEqual(minScore);
      expect(score).toBeLessThanOrEqual(maxScore);
    }
  });

  it('should use default confidence for mock scoring', () => {
    const defaultConfidence = 0.7;
    expect(defaultConfidence).toBeGreaterThanOrEqual(0);
    expect(defaultConfidence).toBeLessThanOrEqual(1);
  });

  it('should not create memories in mock mode', () => {
    // Mock engine only creates scores, not memories
    const mockResult = {
      scoresCreated: 5,
      memoriesCreated: 0,
    };

    expect(mockResult.memoriesCreated).toBe(0);
  });
});

// =====================================================
// RESPONSE STRUCTURE TESTS
// =====================================================

describe('Response Structure', () => {
  it('should return prep mode response structure', () => {
    const prepResponse = {
      ok: true,
      mode: 'prep',
      message: 'Prep complete: 5 scores, 3 memories, 2 targets, 4 agent measurements',
      data: {
        playbookUsed: 'Companion Playbook',
        scoresCreated: 5,
        memoriesCreated: 3,
        deltasComputed: 1,
        agentMeasurements: 4,
        personalityObservationCreated: true,
        personalityProfileUpdated: true,
        aggregateSpecsRun: 2,
        rewardScore: 0.85,
        callTargetsCreated: 2,
        callerTargetsCreated: 3,
        targetsValidated: 1,
        callerTargetsAggregated: 5,
      },
      logs: [],
      duration: 1234,
    };

    expect(prepResponse.ok).toBe(true);
    expect(prepResponse.mode).toBe('prep');
    expect(prepResponse.data).toBeDefined();
    expect(prepResponse.logs).toBeDefined();
    expect(prepResponse.duration).toBeDefined();
    // Prompt should NOT be in prep response
    expect((prepResponse as any).prompt).toBeUndefined();
  });

  it('should return prompt mode response structure', () => {
    const promptResponse = {
      ok: true,
      mode: 'prompt',
      message: 'Full pipeline complete with prompt',
      data: {
        scoresCreated: 5,
        promptId: 'prompt-123',
        promptLength: 2500,
      },
      prompt: 'You are a friendly AI assistant...',
      logs: [],
      duration: 2345,
    };

    expect(promptResponse.ok).toBe(true);
    expect(promptResponse.mode).toBe('prompt');
    expect(promptResponse.prompt).toBeDefined();
    expect(promptResponse.prompt.length).toBeGreaterThan(0);
  });

  it('should include logs array in all responses', () => {
    const responseWithLogs = {
      logs: [
        { timestamp: '2025-01-01T00:00:00.000Z', level: 'info', message: 'Pipeline started' },
        { timestamp: '2025-01-01T00:00:01.000Z', level: 'info', message: 'EXTRACT complete' },
        { timestamp: '2025-01-01T00:00:02.000Z', level: 'warn', message: 'No specs found' },
      ],
    };

    expect(Array.isArray(responseWithLogs.logs)).toBe(true);
    expect(responseWithLogs.logs[0].level).toBe('info');
    expect(responseWithLogs.logs[2].level).toBe('warn');
  });
});

// =====================================================
// AGGREGATION TESTS
// =====================================================

describe('Personality Aggregation', () => {
  it('should compute time-weighted average with decay', () => {
    const halfLifeDays = 30;
    const now = new Date();

    // Score from today (full weight)
    const todayDate = now;
    const todayAgeMs = now.getTime() - todayDate.getTime();
    const todayAgeDays = todayAgeMs / (1000 * 60 * 60 * 24);
    const todayWeight = Math.exp((-Math.log(2) * todayAgeDays) / halfLifeDays);
    expect(todayWeight).toBeCloseTo(1.0, 5);

    // Score from 30 days ago (half weight)
    const thirtyDaysAgo = new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000);
    const oldAgeMs = now.getTime() - thirtyDaysAgo.getTime();
    const oldAgeDays = oldAgeMs / (1000 * 60 * 60 * 24);
    const oldWeight = Math.exp((-Math.log(2) * oldAgeDays) / halfLifeDays);
    expect(oldWeight).toBeCloseTo(0.5, 2);
  });

  it('should map trait IDs to personality fields', () => {
    const defaultTraitMapping = {
      'B5-O': 'openness',
      'B5-C': 'conscientiousness',
      'B5-E': 'extraversion',
      'B5-A': 'agreeableness',
      'B5-N': 'neuroticism',
    };

    expect(defaultTraitMapping['B5-O']).toBe('openness');
    expect(defaultTraitMapping['B5-E']).toBe('extraversion');
  });

  it('should compute confidence that grows with more data', () => {
    const confidenceGrowthBase = 0.5;
    const confidenceGrowthPerCall = 0.1;
    const maxAggregatedConfidence = 0.95;

    // 1 call: 0.5 + 0.1 = 0.6
    const conf1 = Math.min(maxAggregatedConfidence, confidenceGrowthBase + 1 * confidenceGrowthPerCall);
    expect(conf1).toBe(0.6);

    // 5 calls: 0.5 + 0.5 = 1.0 -> capped at 0.95
    const conf5 = Math.min(maxAggregatedConfidence, confidenceGrowthBase + 5 * confidenceGrowthPerCall);
    expect(conf5).toBe(0.95);
  });
});

// =====================================================
// LOGGER TESTS
// =====================================================

describe('Logger Utility', () => {
  it('should track log entries with timestamps', () => {
    const logs: Array<{ timestamp: string; level: string; message: string; data?: any }> = [];

    const log = {
      info: (message: string, data?: any) => {
        logs.push({ timestamp: new Date().toISOString(), level: 'info', message, data });
      },
      warn: (message: string, data?: any) => {
        logs.push({ timestamp: new Date().toISOString(), level: 'warn', message, data });
      },
      error: (message: string, data?: any) => {
        logs.push({ timestamp: new Date().toISOString(), level: 'error', message, data });
      },
    };

    log.info('Test info');
    log.warn('Test warning', { code: 'W001' });
    log.error('Test error', { stack: 'trace' });

    expect(logs.length).toBe(3);
    expect(logs[0].level).toBe('info');
    expect(logs[1].level).toBe('warn');
    expect(logs[2].level).toBe('error');
    expect(logs[1].data).toEqual({ code: 'W001' });
  });

  it('should track duration from start', () => {
    const startTime = Date.now();

    // Simulate some work
    const fakeDelay = 100; // ms

    const getDuration = () => Date.now() - startTime;

    // Duration should be >= 0
    expect(getDuration()).toBeGreaterThanOrEqual(0);
  });
});

// =====================================================
// INTEGRATION-STYLE TESTS (MOCKED)
// =====================================================

describe('Pipeline Integration (Mocked)', () => {
  beforeEach(() => {
    vi.clearAllMocks();
    setupFullMocks();
  });

  function setupFullMocks() {
    // Call exists
    mockPrisma.call.findUnique.mockResolvedValue({
      id: 'call-123',
      transcript: 'Customer: I live in London and I am curious about learning.',
      createdAt: new Date(),
    });

    // Caller with domain
    mockPrisma.caller.findUnique.mockResolvedValue({
      id: 'caller-456',
      domainId: 'domain-1',
      domain: { slug: 'companion', name: 'Companion' },
    });

    // No SUPERVISE spec (use defaults)
    mockPrisma.analysisSpec.findFirst.mockResolvedValue(null);

    // Empty specs (fallback mode)
    mockPrisma.analysisSpec.findMany.mockResolvedValue([]);

    // Empty scores
    mockPrisma.callScore.findMany.mockResolvedValue([]);
    mockPrisma.callScore.findFirst.mockResolvedValue(null);

    // No playbook
    mockPrisma.playbook.findFirst.mockResolvedValue(null);

    // No parameters
    mockPrisma.parameter.findMany.mockResolvedValue([]);

    // No behavior measurements
    mockPrisma.behaviorMeasurement.findFirst.mockResolvedValue(null);

    // No personality observation
    mockPrisma.personalityObservation.findUnique.mockResolvedValue(null);

    // No targets
    mockPrisma.callTarget.findMany.mockResolvedValue([]);
    mockPrisma.behaviorTarget.findMany.mockResolvedValue([]);
  }

  it('should run full pipeline in prep mode with mock engine', async () => {
    // This simulates a prep mode run
    // All stages except COMPOSE should run
    const stagesRun = ['EXTRACT', 'SCORE_AGENT', 'AGGREGATE', 'REWARD', 'ADAPT', 'SUPERVISE'];
    const stagesSkipped = ['COMPOSE'];

    expect(stagesRun).not.toContain('COMPOSE');
    expect(stagesSkipped).toContain('COMPOSE');
  });

  it('should handle empty transcript gracefully', async () => {
    mockPrisma.call.findUnique.mockResolvedValue({
      id: 'call-123',
      transcript: '',
    });

    // Should still run but create no scores/memories
    const result = {
      scoresCreated: 0,
      memoriesCreated: 0,
    };

    expect(result.scoresCreated).toBe(0);
    expect(result.memoriesCreated).toBe(0);
  });

  it('should handle null transcript gracefully', async () => {
    mockPrisma.call.findUnique.mockResolvedValue({
      id: 'call-123',
      transcript: null,
    });

    // Should treat null transcript as empty string
    const transcript = null;
    const safeTranscript = transcript || '';

    expect(safeTranscript).toBe('');
  });
});

// =====================================================
// JSON PARSING AND RECOVERY TESTS
// =====================================================

describe('JSON Parsing and Recovery', () => {
  it('should parse valid JSON response', () => {
    const validJson = JSON.stringify({
      scores: { 'B5-O': { score: 0.75, confidence: 0.8 } },
      memories: [],
    });

    const parsed = JSON.parse(validJson);
    expect(parsed.scores['B5-O'].score).toBe(0.75);
  });

  it('should strip markdown code blocks from response', () => {
    const markdownWrapped = '```json\n{"score": 0.5}\n```';

    let jsonContent = markdownWrapped.trim();
    if (jsonContent.startsWith('```')) {
      jsonContent = jsonContent.replace(/^```(?:json)?\s*\n?/, '').replace(/\n?```\s*$/, '');
    }

    expect(jsonContent).toBe('{"score": 0.5}');
    const parsed = JSON.parse(jsonContent);
    expect(parsed.score).toBe(0.5);
  });

  it('should handle markdown blocks without json label', () => {
    const markdownWrapped = '```\n{"score": 0.5}\n```';

    let jsonContent = markdownWrapped.trim();
    if (jsonContent.startsWith('```')) {
      jsonContent = jsonContent.replace(/^```(?:json)?\s*\n?/, '').replace(/\n?```\s*$/, '');
    }

    expect(jsonContent).toBe('{"score": 0.5}');
  });

  it('should attempt to recover truncated JSON by adding closing braces', () => {
    const truncatedJson = '{"scores": {"B5-O": {"score": 0.5}';

    let fixed = truncatedJson;
    const openBraces = (fixed.match(/\{/g) || []).length;
    const closeBraces = (fixed.match(/\}/g) || []).length;
    const openBrackets = (fixed.match(/\[/g) || []).length;
    const closeBrackets = (fixed.match(/\]/g) || []).length;

    // Add missing closing characters
    for (let i = 0; i < openBrackets - closeBrackets; i++) fixed += ']';
    for (let i = 0; i < openBraces - closeBraces; i++) fixed += '}';

    expect(fixed).toBe('{"scores": {"B5-O": {"score": 0.5}}}');
    const parsed = JSON.parse(fixed);
    expect(parsed.scores['B5-O'].score).toBe(0.5);
  });

  it('should recover JSON with missing array brackets', () => {
    const truncatedJson = '{"items": [1, 2, 3';

    let fixed = truncatedJson;
    const openBraces = (fixed.match(/\{/g) || []).length;
    const closeBraces = (fixed.match(/\}/g) || []).length;
    const openBrackets = (fixed.match(/\[/g) || []).length;
    const closeBrackets = (fixed.match(/\]/g) || []).length;

    for (let i = 0; i < openBrackets - closeBrackets; i++) fixed += ']';
    for (let i = 0; i < openBraces - closeBraces; i++) fixed += '}';

    expect(fixed).toBe('{"items": [1, 2, 3]}');
    const parsed = JSON.parse(fixed);
    expect(parsed.items).toEqual([1, 2, 3]);
  });
});

// =====================================================
// SCORE CLAMPING TESTS
// =====================================================

describe('Score Clamping', () => {
  it('should clamp scores to 0-1 range', () => {
    const testCases = [
      { input: -0.5, expected: 0 },
      { input: 0, expected: 0 },
      { input: 0.5, expected: 0.5 },
      { input: 1, expected: 1 },
      { input: 1.5, expected: 1 },
    ];

    for (const { input, expected } of testCases) {
      const clamped = Math.max(0, Math.min(1, input));
      expect(clamped).toBe(expected);
    }
  });

  it('should use default score when undefined', () => {
    const rawScore = undefined;
    const defaultScore = 0.5;
    const score = Math.max(0, Math.min(1, rawScore || defaultScore));
    expect(score).toBe(0.5);
  });

  it('should clamp confidence to 0-1 range', () => {
    const rawConfidence = 1.2;
    const defaultConfidence = 0.7;
    const confidence = Math.max(0, Math.min(1, rawConfidence || defaultConfidence));
    expect(confidence).toBe(1);
  });
});

// =====================================================
// PLAYBOOK SPEC SELECTION TESTS
// =====================================================

describe('Playbook Spec Selection', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  it('should fallback to all DOMAIN specs when caller has no domain', () => {
    // When caller.domainId is null
    const caller = { id: 'caller-1', domainId: null };
    const shouldFallback = !caller.domainId;
    expect(shouldFallback).toBe(true);
  });

  it('should fallback to all DOMAIN specs when no playbook published', () => {
    // When no published playbook found for domain
    const playbook = null;
    const shouldFallback = !playbook;
    expect(shouldFallback).toBe(true);
  });

  it('should combine SYSTEM and DOMAIN specs without duplicates', () => {
    const systemSpecs = [
      { id: 'spec-1', slug: 'system-measure', outputType: 'MEASURE' },
      { id: 'spec-2', slug: 'system-learn', outputType: 'LEARN' },
    ];

    const playbookSpecs = [
      { id: 'spec-3', slug: 'domain-measure', outputType: 'MEASURE' },
      { id: 'spec-1', slug: 'system-measure', outputType: 'MEASURE' }, // duplicate
    ];

    const allSpecIds = new Set<string>();
    const combinedSpecs: Array<{ id: string; slug: string; outputType: string }> = [];

    for (const spec of [...systemSpecs, ...playbookSpecs]) {
      if (!allSpecIds.has(spec.id)) {
        allSpecIds.add(spec.id);
        combinedSpecs.push(spec);
      }
    }

    expect(combinedSpecs.length).toBe(3); // Not 4, because spec-1 is deduplicated
    expect(allSpecIds.has('spec-1')).toBe(true);
    expect(allSpecIds.has('spec-2')).toBe(true);
    expect(allSpecIds.has('spec-3')).toBe(true);
  });
});

// =====================================================
// REWARD COMPUTATION TESTS
// =====================================================

describe('Reward Computation', () => {
  it('should compute reward as 1 - average_diff', () => {
    const diffs = [
      { diff: 0.1 }, // Close to target
      { diff: 0.2 },
      { diff: 0.0 }, // Perfect match
    ];

    const avgDiff = diffs.reduce((sum, d) => sum + d.diff, 0) / diffs.length;
    const reward = Math.max(0, 1 - avgDiff);

    expect(avgDiff).toBeCloseTo(0.1, 5);
    expect(reward).toBeCloseTo(0.9, 5);
  });

  it('should return 0.5 reward when no measurements', () => {
    const measurementsCount = 0;
    const defaultReward = 0.5;
    const reward = measurementsCount === 0 ? defaultReward : 0.8;
    expect(reward).toBe(0.5);
  });

  it('should use 0.5 as default target when no BehaviorTarget exists', () => {
    const target = undefined;
    const targetValue = target ?? 0.5;
    expect(targetValue).toBe(0.5);
  });

  it('should compute diff as absolute difference', () => {
    const actual = 0.3;
    const target = 0.7;
    const diff = Math.abs(actual - target);
    expect(diff).toBeCloseTo(0.4, 5);
  });
});

// =====================================================
// ADAPT TARGET COMPUTATION TESTS
// =====================================================

describe('Adapt Target Computation', () => {
  it('should nudge target toward center in mock mode', () => {
    const mockBehavior = { scoreRangeMin: 0.4, scoreRangeMax: 0.8, nudgeFactor: 0.2 };
    const center = (mockBehavior.scoreRangeMin + mockBehavior.scoreRangeMax) / 2;

    expect(center).toBeCloseTo(0.6, 5);

    // Low score should be nudged up
    const lowScore = 0.3;
    const nudgedLow = lowScore + (center - lowScore) * mockBehavior.nudgeFactor;
    expect(nudgedLow).toBeCloseTo(0.36, 5);

    // High score should be nudged down
    const highScore = 0.9;
    const nudgedHigh = highScore + (center - highScore) * mockBehavior.nudgeFactor;
    expect(nudgedHigh).toBeCloseTo(0.84, 5);
  });

  it('should aggregate CallerTargets with time-weighted averaging', () => {
    const targets = [
      { value: 0.8, confidence: 0.9, ageDays: 0 }, // Today
      { value: 0.6, confidence: 0.8, ageDays: 30 }, // 30 days old
    ];

    const halfLifeDays = 30;
    let weightedSum = 0;
    let totalWeight = 0;

    for (const t of targets) {
      const decayWeight = Math.exp((-Math.log(2) * t.ageDays) / halfLifeDays);
      const weight = decayWeight * t.confidence;
      weightedSum += t.value * weight;
      totalWeight += weight;
    }

    const avgValue = weightedSum / totalWeight;

    // Today's value (0.8) should have more weight than 30-day-old value (0.6)
    expect(avgValue).toBeGreaterThan(0.6);
    expect(avgValue).toBeLessThan(0.8);
  });
});

// =====================================================
// PIPELINE STAGE EXECUTOR TESTS
// =====================================================

describe('Stage Executor Registry', () => {
  it('should have executor for all default stages', () => {
    const defaultStages = ['EXTRACT', 'SCORE_AGENT', 'AGGREGATE', 'REWARD', 'ADAPT', 'SUPERVISE', 'COMPOSE'];

    // All stages should have an executor defined
    for (const stage of defaultStages) {
      expect(typeof stage).toBe('string');
    }
  });

  it('should skip stage when requiresMode does not match', () => {
    const mode = 'prep';
    const stage = { name: 'COMPOSE', requiresMode: 'prompt' as const };

    const shouldSkip = stage.requiresMode && stage.requiresMode !== mode;
    expect(shouldSkip).toBe(true);
  });

  it('should run stage when no requiresMode specified', () => {
    const mode = 'prep';
    const stage = { name: 'EXTRACT', requiresMode: undefined };

    const shouldSkip = stage.requiresMode && stage.requiresMode !== mode;
    expect(shouldSkip).toBeFalsy();
  });

  it('should run stage when requiresMode matches', () => {
    const mode = 'prompt';
    const stage = { name: 'COMPOSE', requiresMode: 'prompt' as const };

    const shouldSkip = stage.requiresMode && stage.requiresMode !== mode;
    expect(shouldSkip).toBe(false);
  });
});
